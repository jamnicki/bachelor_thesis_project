{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.cli.train import train\n",
    "from spacy.cli.evaluate import evaluate\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "import argilla as rg\n",
    "\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from jsonlines import jsonlines\n",
    "import random\n",
    "from time import time as etime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"random_sm10\"\n",
    "\n",
    "_start_etime_str = str(etime()).replace(\".\", \"f\")\n",
    "DATA_DIR = Path(\"data\")\n",
    "TRAIN_DB = DATA_DIR / Path(\"inzynierka-kpwr-train-3.spacy\")\n",
    "TEST_DB = DATA_DIR / Path(\"inzynierka-kpwr-test-3.spacy\")\n",
    "TEMP_DB = DATA_DIR / Path(\"temp-train.spacy\")\n",
    "LOGS_DIR = Path(\"logs\")\n",
    "CONFIG_DIR = Path(\"config\") / Path(\"spacy\")\n",
    "CONFIG = CONFIG_DIR / Path(\"config_sm.cfg\")\n",
    "MODELS_DIR = Path(\"models\")\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "MODEL_OUT = MODELS_DIR / Path(f\"{NAME}__{_start_etime_str}.spacy\")\n",
    "MODEL_LAST = MODEL_OUT / Path(\"model-last\")\n",
    "METRICS_OUT = LOGS_DIR / Path(f\"{NAME}__{_start_etime_str}.metrics.jsonl\")\n",
    "\n",
    "SEED = 42\n",
    "SPANS_KEY = \"sc\"\n",
    "N_INSTANCES = 10\n",
    "\n",
    "random.seed(SEED)\n",
    "assert not MODEL_OUT.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_random(records, exclude, n_instances):\n",
    "    \"\"\"Random query strategy\"\"\"\n",
    "    n_queried = 0\n",
    "    max_idx = len(records) - 1\n",
    "    while n_queried < n_instances:\n",
    "        idx = random.randint(0, max_idx)\n",
    "        if idx not in exclude:\n",
    "            exclude.add(idx)\n",
    "            n_queried += 1\n",
    "            yield idx, records[idx]\n",
    "\n",
    "def log_results(results, out):\n",
    "    \"\"\"Log results to a file\"\"\"\n",
    "    with jsonlines.open(out, mode=\"w\") as writer:\n",
    "        writer.write(results)\n",
    "\n",
    "def _docs_train(docbin_path, lang=\"pl\"):\n",
    "    \"\"\"Get docs from Docbin using blank nlp object's vocabulary.\"\"\"\n",
    "    nlp = spacy.blank(lang)\n",
    "    docs_train = list(DocBin().from_disk(docbin_path).get_docs(nlp.vocab))\n",
    "    return docs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more data to query\n",
      "\u001b[38;5;2m✔ Created output directory:\n",
      "models/random_sm_batch_10__1668441930f2908602.spacy\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory:\n",
      "models/random_sm_batch_10__1668441930f2908602.spacy\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'spancat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS SPANCAT  SPANS_SC_F  SPANS_SC_P  SPANS_SC_R  SCORE \n",
      "---  ------  ------------  ------------  ----------  ----------  ----------  ------\n",
      "  0       0         10.74        256.19        1.82        0.94       32.12    0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo more data to query\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m db\u001b[39m.\u001b[39mto_disk(TEMP_DB)\n\u001b[0;32m---> 25\u001b[0m train(CONFIG,\n\u001b[1;32m     26\u001b[0m     output_path\u001b[39m=\u001b[39;49mMODEL_OUT,\n\u001b[1;32m     27\u001b[0m     overrides\u001b[39m=\u001b[39;49m{\n\u001b[1;32m     28\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mtraining.seed\u001b[39;49m\u001b[39m\"\u001b[39;49m: SEED,\n\u001b[1;32m     29\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpaths.train\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mstr\u001b[39;49m(TEMP_DB),\n\u001b[1;32m     30\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpaths.dev\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mstr\u001b[39;49m(TEST_DB)\n\u001b[1;32m     31\u001b[0m     }\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m eval_metrics \u001b[39m=\u001b[39m evaluate(MODEL_LAST, TEST_DB)\n\u001b[1;32m     35\u001b[0m log_metrics(eval_metrics,\n\u001b[1;32m     36\u001b[0m             out\u001b[39m=\u001b[39mMETRICS_OUT)\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/spacy/cli/train.py:75\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config_path, output_path, use_gpu, overrides)\u001b[0m\n\u001b[1;32m     73\u001b[0m msg\u001b[39m.\u001b[39mgood(\u001b[39m\"\u001b[39m\u001b[39mInitialized pipeline\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m msg\u001b[39m.\u001b[39mdivider(\u001b[39m\"\u001b[39m\u001b[39mTraining pipeline\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m train_nlp(nlp, output_path, use_gpu\u001b[39m=\u001b[39;49muse_gpu, stdout\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mstdout, stderr\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mstderr)\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/spacy/training/loop.py:105\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(nlp, output_path, use_gpu, stdout, stderr)\u001b[0m\n\u001b[1;32m    103\u001b[0m     log_step, finalize_logger \u001b[39m=\u001b[39m train_logger(nlp, stdout, stderr)\n\u001b[1;32m    104\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mfor\u001b[39;00m batch, info, is_best_checkpoint \u001b[39min\u001b[39;00m training_step_iterator:\n\u001b[1;32m    106\u001b[0m         \u001b[39mif\u001b[39;00m is_best_checkpoint \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m             \u001b[39mwith\u001b[39;00m nlp\u001b[39m.\u001b[39mselect_pipes(disable\u001b[39m=\u001b[39mfrozen_components):\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/spacy/training/loop.py:203\u001b[0m, in \u001b[0;36mtrain_while_improving\u001b[0;34m(nlp, optimizer, train_data, evaluate, dropout, eval_frequency, accumulate_gradient, patience, max_steps, exclude, annotating_components)\u001b[0m\n\u001b[1;32m    201\u001b[0m dropout \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(dropouts)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mfor\u001b[39;00m subbatch \u001b[39min\u001b[39;00m subdivide_batch(batch, accumulate_gradient):\n\u001b[0;32m--> 203\u001b[0m     nlp\u001b[39m.\u001b[39;49mupdate(\n\u001b[1;32m    204\u001b[0m         subbatch,\n\u001b[1;32m    205\u001b[0m         drop\u001b[39m=\u001b[39;49mdropout,\n\u001b[1;32m    206\u001b[0m         losses\u001b[39m=\u001b[39;49mlosses,\n\u001b[1;32m    207\u001b[0m         sgd\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    208\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m    209\u001b[0m         annotates\u001b[39m=\u001b[39;49mannotating_components,\n\u001b[1;32m    210\u001b[0m     )\n\u001b[1;32m    211\u001b[0m \u001b[39m# TODO: refactor this so we don't have to run it separately in here\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39mfor\u001b[39;00m name, proc \u001b[39min\u001b[39;00m nlp\u001b[39m.\u001b[39mpipeline:\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/spacy/language.py:1170\u001b[0m, in \u001b[0;36mLanguage.update\u001b[0;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[39mfor\u001b[39;00m name, proc \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline:\n\u001b[1;32m   1168\u001b[0m     \u001b[39m# ignore statements are used here because mypy ignores hasattr\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1170\u001b[0m         proc\u001b[39m.\u001b[39;49mupdate(examples, sgd\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, losses\u001b[39m=\u001b[39;49mlosses, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg[name])  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m     \u001b[39mif\u001b[39;00m sgd \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1172\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1173\u001b[0m             name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude\n\u001b[1;32m   1174\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(proc, ty\u001b[39m.\u001b[39mTrainableComponent)\n\u001b[1;32m   1175\u001b[0m             \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mis_trainable\n\u001b[1;32m   1176\u001b[0m             \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mmodel \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1177\u001b[0m         ):\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/spacy/pipeline/tok2vec.py:168\u001b[0m, in \u001b[0;36mTok2Vec.update\u001b[0;34m(self, examples, drop, sgd, losses)\u001b[0m\n\u001b[1;32m    166\u001b[0m docs \u001b[39m=\u001b[39m [eg\u001b[39m.\u001b[39mpredicted \u001b[39mfor\u001b[39;00m eg \u001b[39min\u001b[39;00m examples]\n\u001b[1;32m    167\u001b[0m set_dropout_rate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, drop)\n\u001b[0;32m--> 168\u001b[0m tokvecs, bp_tokvecs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mbegin_update(docs)\n\u001b[1;32m    169\u001b[0m d_tokvecs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39malloc2f(\u001b[39m*\u001b[39mt2v\u001b[39m.\u001b[39mshape) \u001b[39mfor\u001b[39;00m t2v \u001b[39min\u001b[39;00m tokvecs]\n\u001b[1;32m    170\u001b[0m losses\u001b[39m.\u001b[39msetdefault(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39m0.0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/model.py:309\u001b[0m, in \u001b[0;36mModel.begin_update\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbegin_update\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable[[InT], OutT]]:\n\u001b[1;32m    303\u001b[0m     \u001b[39m\"\"\"Run the model over a batch of data, returning the output and a\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39m    callback to complete the backward pass. A tuple (Y, finish_update),\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m    where Y is a batch of output data, and finish_update is a callback that\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[39m    takes the gradient with respect to the output and an optimizer function,\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m    and returns the gradient with respect to the input.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/layers/with_array.py:38\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m](Xseq, is_train)\n\u001b[1;32m     37\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/layers/with_array.py:73\u001b[0m, in \u001b[0;36m_list_forward\u001b[0;34m(model, Xs, is_train)\u001b[0m\n\u001b[1;32m     71\u001b[0m lengths \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39masarray1i([\u001b[39mlen\u001b[39m(seq) \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m Xs])\n\u001b[1;32m     72\u001b[0m Xf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(Xs, pad\u001b[39m=\u001b[39mpad)\n\u001b[0;32m---> 73\u001b[0m Yf, get_dXf \u001b[39m=\u001b[39m layer(Xf, is_train)\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYs: ListXd) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ListXd:\n\u001b[1;32m     76\u001b[0m     dYf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(dYs, pad\u001b[39m=\u001b[39mpad)\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/layers/residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m d_output \u001b[39m+\u001b[39m dX\n\u001b[0;32m---> 41\u001b[0m Y, backprop_layer \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m](X, is_train)\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(X, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m [X[i] \u001b[39m+\u001b[39m Y[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X))], backprop\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "    \u001b[0;31m[... skipping similar frames: Model.__call__ at line 291 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/layers/layernorm.py:25\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model: Model[InT, InT], X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[InT, Callable]:\n\u001b[0;32m---> 25\u001b[0m     N, mu, var \u001b[39m=\u001b[39m _get_moments(model\u001b[39m.\u001b[39;49mops, X)\n\u001b[1;32m     26\u001b[0m     Xhat \u001b[39m=\u001b[39m (X \u001b[39m-\u001b[39m mu) \u001b[39m*\u001b[39m var \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m \u001b[39m2.0\u001b[39m)\n\u001b[1;32m     27\u001b[0m     Y, backprop_rescale \u001b[39m=\u001b[39m _begin_update_scale_shift(model, Xhat)\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/thinc/layers/layernorm.py:76\u001b[0m, in \u001b[0;36m_get_moments\u001b[0;34m(ops, X)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_moments\u001b[39m(ops: Ops, X: Floats2d) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Floats2d, Floats2d, Floats2d]:\n\u001b[1;32m     74\u001b[0m     \u001b[39m# TODO: Do mean methods\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     mu: Floats2d \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 76\u001b[0m     var: Floats2d \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mvar(axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, keepdims\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39m+\u001b[39m \u001b[39m1e-08\u001b[39m\n\u001b[1;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Floats2d, ops\u001b[39m.\u001b[39masarray_f([X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]])), mu, var\n",
      "File \u001b[0;32m~/miniconda3/envs/inzynierka/lib/python3.8/site-packages/numpy/core/_methods.py:247\u001b[0m, in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39m# Most general case; includes handling object arrays containing imaginary\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39m# numbers and complex types with non-native byteorder\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m     x \u001b[39m=\u001b[39m um\u001b[39m.\u001b[39mmultiply(x, um\u001b[39m.\u001b[39mconjugate(x), out\u001b[39m=\u001b[39mx)\u001b[39m.\u001b[39mreal\n\u001b[0;32m--> 247\u001b[0m ret \u001b[39m=\u001b[39m umr_sum(x, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims, where\u001b[39m=\u001b[39;49mwhere)\n\u001b[1;32m    249\u001b[0m \u001b[39m# Compute degrees of freedom and make sure it is not negative.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m rcount \u001b[39m=\u001b[39m um\u001b[39m.\u001b[39mmaximum(rcount \u001b[39m-\u001b[39m ddof, \u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "docs_train = _docs_train(TRAIN_DB)\n",
    "docs_train_len = len(docs_train)\n",
    "\n",
    "iteration = 1\n",
    "max_iters = 10\n",
    "spans_queried = 0\n",
    "spans_num_history = []\n",
    "db = DocBin()\n",
    "queried = set()\n",
    "while True:\n",
    "    if iteration > max_iters or len(queried) >= docs_train_len:\n",
    "        break\n",
    "\n",
    "    for q_idx, q_doc in query_random(docs_train, queried, N_INSTANCES):\n",
    "        queried.add(q_idx)\n",
    "        db.add(q_doc)\n",
    "        spans_queried += len(q_doc.spans[SPANS_KEY])\n",
    "    spans_num_history.append(spans_queried)\n",
    "\n",
    "    db.to_disk(TEMP_DB)\n",
    "\n",
    "    train(CONFIG,\n",
    "            output_path=MODEL_OUT,\n",
    "            overrides={\n",
    "                \"training.seed\": SEED,\n",
    "                \"paths.train\": str(TEMP_DB),\n",
    "                \"paths.dev\": str(TEST_DB)\n",
    "            })\n",
    "\n",
    "    eval_metrics = evaluate(MODEL_LAST, TEST_DB)\n",
    "\n",
    "    results = {\"_iteration\": iteration, \"_spans_num\": spans_queried}\n",
    "    results.update(eval_metrics)\n",
    "\n",
    "    log_results(results,\n",
    "                out=METRICS_OUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('inzynierka')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f93f2a12df6eac11490746e2731e653b567b740467f1f6260fc82eafdd8ce6df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
